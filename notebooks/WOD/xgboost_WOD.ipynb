{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18296, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>mint_count_per_week</th>\n",
       "      <th>burn_count_per_week</th>\n",
       "      <th>mint_ratio</th>\n",
       "      <th>swap_ratio</th>\n",
       "      <th>burn_ratio</th>\n",
       "      <th>mint_mean_period</th>\n",
       "      <th>swap_mean_period</th>\n",
       "      <th>burn_mean_period</th>\n",
       "      <th>swap_in_per_week</th>\n",
       "      <th>swap_out_per_week</th>\n",
       "      <th>swap_rate</th>\n",
       "      <th>lp_avg</th>\n",
       "      <th>lp_std</th>\n",
       "      <th>lp_creator_holding_ratio</th>\n",
       "      <th>lp_lock_ratio</th>\n",
       "      <th>token_burn_ratio</th>\n",
       "      <th>token_creator_holding_ratio</th>\n",
       "      <th>number_of_token_creation_of_creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3cd1c0b98be4451ca51265bbaeb76cf7b31e1c02</td>\n",
       "      <td>0</td>\n",
       "      <td>44.071475</td>\n",
       "      <td>16.466820</td>\n",
       "      <td>0.148132</td>\n",
       "      <td>0.796520</td>\n",
       "      <td>0.055348</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>0.074894</td>\n",
       "      <td>0.221980</td>\n",
       "      <td>100.871903</td>\n",
       "      <td>136.103828</td>\n",
       "      <td>0.741002</td>\n",
       "      <td>0.119760</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.302617e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x0c52de7bb69edd144d58d772fab1cd196919f5ef</td>\n",
       "      <td>0</td>\n",
       "      <td>13.813171</td>\n",
       "      <td>6.316279</td>\n",
       "      <td>0.169770</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>42.502064</td>\n",
       "      <td>18.732391</td>\n",
       "      <td>2.266527</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.431320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa00d47b4b304792eb07b09233467b690db847c91</td>\n",
       "      <td>0</td>\n",
       "      <td>27.366327</td>\n",
       "      <td>17.779613</td>\n",
       "      <td>0.068019</td>\n",
       "      <td>0.887790</td>\n",
       "      <td>0.044191</td>\n",
       "      <td>0.131459</td>\n",
       "      <td>0.384409</td>\n",
       "      <td>0.191228</td>\n",
       "      <td>165.965722</td>\n",
       "      <td>191.224332</td>\n",
       "      <td>0.867757</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>4.649864</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.064726</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x114e40ba90e9d8b002bc6936e3299daa393017bb</td>\n",
       "      <td>0</td>\n",
       "      <td>10.559028</td>\n",
       "      <td>1.912477</td>\n",
       "      <td>0.056257</td>\n",
       "      <td>0.933553</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.036312</td>\n",
       "      <td>0.077704</td>\n",
       "      <td>0.140362</td>\n",
       "      <td>90.398212</td>\n",
       "      <td>84.822399</td>\n",
       "      <td>1.065397</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>4.754048</td>\n",
       "      <td>1.480000e-08</td>\n",
       "      <td>0.693921</td>\n",
       "      <td>3.748588e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x40829a59080a12f16bb8fba22354a6a42c810aab</td>\n",
       "      <td>0</td>\n",
       "      <td>9.662390</td>\n",
       "      <td>6.450369</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.959774</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.206316</td>\n",
       "      <td>0.171454</td>\n",
       "      <td>204.911119</td>\n",
       "      <td>179.530891</td>\n",
       "      <td>1.141202</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>5.466877</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.790202</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  label  mint_count_per_week  \\\n",
       "0  0x3cd1c0b98be4451ca51265bbaeb76cf7b31e1c02      0            44.071475   \n",
       "1  0x0c52de7bb69edd144d58d772fab1cd196919f5ef      0            13.813171   \n",
       "2  0xa00d47b4b304792eb07b09233467b690db847c91      0            27.366327   \n",
       "3  0x114e40ba90e9d8b002bc6936e3299daa393017bb      0            10.559028   \n",
       "4  0x40829a59080a12f16bb8fba22354a6a42c810aab      0             9.662390   \n",
       "\n",
       "   burn_count_per_week  mint_ratio  swap_ratio  burn_ratio  mint_mean_period  \\\n",
       "0            16.466820    0.148132    0.796520    0.055348          0.034508   \n",
       "1             6.316279    0.169770    0.752600    0.077630          0.040580   \n",
       "2            17.779613    0.068019    0.887790    0.044191          0.131459   \n",
       "3             1.912477    0.056257    0.933553    0.010189          0.036312   \n",
       "4             6.450369    0.024123    0.959774    0.016104          0.088733   \n",
       "\n",
       "   swap_mean_period  burn_mean_period  swap_in_per_week  swap_out_per_week  \\\n",
       "0          0.074894          0.221980        100.871903         136.103828   \n",
       "1          0.050907          0.083953         42.502064          18.732391   \n",
       "2          0.384409          0.191228        165.965722         191.224332   \n",
       "3          0.077704          0.140362         90.398212          84.822399   \n",
       "4          0.206316          0.171454        204.911119         179.530891   \n",
       "\n",
       "   swap_rate    lp_avg    lp_std  lp_creator_holding_ratio  lp_lock_ratio  \\\n",
       "0   0.741002  0.119760  0.126458              0.000000e+00       0.000000   \n",
       "1   2.266527  0.332226  0.431320              0.000000e+00       0.000000   \n",
       "2   0.867757  0.377358  4.649864              0.000000e+00       0.064726   \n",
       "3   1.065397  0.467290  4.754048              1.480000e-08       0.693921   \n",
       "4   1.141202  0.476190  5.466877              0.000000e+00       0.790202   \n",
       "\n",
       "   token_burn_ratio  token_creator_holding_ratio  \\\n",
       "0      0.000000e+00                 1.302617e-01   \n",
       "1      4.000000e-07                 1.000000e-08   \n",
       "2      0.000000e+00                 0.000000e+00   \n",
       "3      3.748588e-03                 0.000000e+00   \n",
       "4      0.000000e+00                 1.000000e-08   \n",
       "\n",
       "   number_of_token_creation_of_creator  \n",
       "0                                    1  \n",
       "1                                    1  \n",
       "2                                    1  \n",
       "3                                    1  \n",
       "4                                    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./../../datasets/Dataset_WOD.csv')\n",
    "\n",
    "dataframe.dropna(inplace=True)\n",
    "dataframe.rename(columns=lambda x : x.lower(), inplace=True)\n",
    "\n",
    "dataframe['label'] = label_encoder.fit_transform(dataframe['label'])\n",
    "print(dataframe.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe.drop(columns=['id', 'label'], axis=1)\n",
    "y = dataframe['label']\n",
    "scaler = StandardScaler().fit(x)\n",
    "x = pd.DataFrame(scaler.transform(x))\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>-0.066404</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>-0.546290</td>\n",
       "      <td>0.551036</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.018552</td>\n",
       "      <td>-0.292115</td>\n",
       "      <td>-0.022643</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.029623</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16111</th>\n",
       "      <td>-0.205669</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>-0.811092</td>\n",
       "      <td>0.795566</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>-0.127049</td>\n",
       "      <td>-0.166080</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.026904</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>-0.134003</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>-0.858555</td>\n",
       "      <td>0.839396</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>-1.398682</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>0.751300</td>\n",
       "      <td>2.107890</td>\n",
       "      <td>-0.245496</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.029648</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>-0.066843</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>0.567843</td>\n",
       "      <td>-0.477801</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>0.957414</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.402082</td>\n",
       "      <td>-0.337205</td>\n",
       "      <td>-0.164218</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.029844</td>\n",
       "      <td>-0.109122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>-0.081344</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>-0.727734</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>-1.090690</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.080730</td>\n",
       "      <td>0.539457</td>\n",
       "      <td>-0.247536</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.029844</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>-0.066137</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>1.520101</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.313164</td>\n",
       "      <td>-0.359679</td>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.029844</td>\n",
       "      <td>4.381848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>-0.066401</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>0.593137</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.342892</td>\n",
       "      <td>-0.314636</td>\n",
       "      <td>-0.159250</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>0.326008</td>\n",
       "      <td>-0.029844</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-0.066117</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>0.751874</td>\n",
       "      <td>-0.647742</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>-0.446158</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.460776</td>\n",
       "      <td>-0.269470</td>\n",
       "      <td>-0.250652</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.084915</td>\n",
       "      <td>0.973166</td>\n",
       "      <td>-0.811092</td>\n",
       "      <td>0.709399</td>\n",
       "      <td>0.135641</td>\n",
       "      <td>5.937337</td>\n",
       "      <td>0.866285</td>\n",
       "      <td>2.044829</td>\n",
       "      <td>2.380571</td>\n",
       "      <td>0.669523</td>\n",
       "      <td>-0.143244</td>\n",
       "      <td>-3.218240</td>\n",
       "      <td>5.766867</td>\n",
       "      <td>0.430613</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.025190</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-0.066955</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>1.303966</td>\n",
       "      <td>-1.157568</td>\n",
       "      <td>-0.159520</td>\n",
       "      <td>-0.238152</td>\n",
       "      <td>1.778473</td>\n",
       "      <td>-0.283282</td>\n",
       "      <td>-0.431546</td>\n",
       "      <td>-0.359679</td>\n",
       "      <td>-0.119510</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.135428</td>\n",
       "      <td>-0.025844</td>\n",
       "      <td>-0.227306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14636 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "5265  -0.066404 -0.091209 -0.546290  0.551036 -0.159520 -0.238152  0.982543   \n",
       "16111 -0.205669 -0.091209 -0.811092  0.795566 -0.159520 -0.238152 -0.008706   \n",
       "5217  -0.134003 -0.091209 -0.858555  0.839396 -0.159520 -0.238152 -1.398682   \n",
       "11497 -0.066843 -0.091209  0.567843 -0.477801 -0.159520 -0.238152  0.957414   \n",
       "5133  -0.081344 -0.091209 -0.727734  0.718590 -0.159520 -0.238152 -1.090690   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11284 -0.066137 -0.091209  0.042040  0.007748 -0.159520 -0.238152  1.520101   \n",
       "11964 -0.066401 -0.091209  0.042040  0.007748 -0.159520 -0.238152  0.593137   \n",
       "5390  -0.066117 -0.091209  0.751874 -0.647742 -0.159520 -0.238152 -0.446158   \n",
       "860    0.084915  0.973166 -0.811092  0.709399  0.135641  5.937337  0.866285   \n",
       "15795 -0.066955 -0.091209  1.303966 -1.157568 -0.159520 -0.238152  1.778473   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "5265  -0.283282 -0.018552 -0.292115 -0.022643  0.217816 -0.207025  0.430624   \n",
       "16111 -0.283282  0.035300 -0.127049 -0.166080  0.217816 -0.207025  0.430624   \n",
       "5217  -0.283282  0.751300  2.107890 -0.245496  0.217816 -0.207025  0.430624   \n",
       "11497 -0.283282 -0.402082 -0.337205 -0.164218  0.217816 -0.207025  0.430624   \n",
       "5133  -0.283282 -0.080730  0.539457 -0.247536  0.217816 -0.207025  0.430624   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11284 -0.283282 -0.313164 -0.359679  0.118931  0.217816 -0.207025  0.430624   \n",
       "11964 -0.283282 -0.342892 -0.314636 -0.159250  0.217816 -0.207025  0.430624   \n",
       "5390  -0.283282 -0.460776 -0.269470 -0.250652  0.217816 -0.207025  0.430624   \n",
       "860    2.044829  2.380571  0.669523 -0.143244 -3.218240  5.766867  0.430613   \n",
       "15795 -0.283282 -0.431546 -0.359679 -0.119510  0.217816 -0.207025  0.430624   \n",
       "\n",
       "             14        15        16        17  \n",
       "5265  -0.400687 -0.135428 -0.029623 -0.227306  \n",
       "16111 -0.400687 -0.135428 -0.026904 -0.227306  \n",
       "5217  -0.400687 -0.135428 -0.029648 -0.227306  \n",
       "11497 -0.400687 -0.135428 -0.029844 -0.109122  \n",
       "5133  -0.400687 -0.135428 -0.029844 -0.227306  \n",
       "...         ...       ...       ...       ...  \n",
       "11284 -0.400687 -0.135428 -0.029844  4.381848  \n",
       "11964 -0.400687  0.326008 -0.029844 -0.227306  \n",
       "5390  -0.400687 -0.135428 -0.023335 -0.227306  \n",
       "860   -0.400687 -0.135428 -0.025190 -0.227306  \n",
       "15795 -0.400687 -0.135428 -0.025844 -0.227306  \n",
       "\n",
       "[14636 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier(objective=\"binary:logistic\", n_estimators=20, random_state=42, eval_metric=[\"auc\", \"error\", \"error@0.6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.97864\tvalidation_0-error:0.09508\tvalidation_0-error@0.6:0.02923\n",
      "[1]\tvalidation_0-auc:0.98211\tvalidation_0-error:0.02760\tvalidation_0-error@0.6:0.02568\n",
      "[2]\tvalidation_0-auc:0.98417\tvalidation_0-error:0.02432\tvalidation_0-error@0.6:0.02350\n",
      "[3]\tvalidation_0-auc:0.98473\tvalidation_0-error:0.02322\tvalidation_0-error@0.6:0.02186\n",
      "[4]\tvalidation_0-auc:0.98510\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.02240\n",
      "[5]\tvalidation_0-auc:0.98713\tvalidation_0-error:0.02022\tvalidation_0-error@0.6:0.02131\n",
      "[6]\tvalidation_0-auc:0.98747\tvalidation_0-error:0.02022\tvalidation_0-error@0.6:0.02049\n",
      "[7]\tvalidation_0-auc:0.98738\tvalidation_0-error:0.01940\tvalidation_0-error@0.6:0.01995\n",
      "[8]\tvalidation_0-auc:0.98764\tvalidation_0-error:0.01885\tvalidation_0-error@0.6:0.01995\n",
      "[9]\tvalidation_0-auc:0.98754\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.02077\n",
      "[10]\tvalidation_0-auc:0.98958\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.01967\n",
      "[11]\tvalidation_0-auc:0.98985\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.02104\n",
      "[12]\tvalidation_0-auc:0.98980\tvalidation_0-error:0.01913\tvalidation_0-error@0.6:0.02049\n",
      "[13]\tvalidation_0-auc:0.99018\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.02077\n",
      "[14]\tvalidation_0-auc:0.99024\tvalidation_0-error:0.01967\tvalidation_0-error@0.6:0.02077\n",
      "[15]\tvalidation_0-auc:0.99019\tvalidation_0-error:0.01995\tvalidation_0-error@0.6:0.02158\n",
      "[16]\tvalidation_0-auc:0.99042\tvalidation_0-error:0.01940\tvalidation_0-error@0.6:0.02077\n",
      "[17]\tvalidation_0-auc:0.99054\tvalidation_0-error:0.02022\tvalidation_0-error@0.6:0.02077\n",
      "[18]\tvalidation_0-auc:0.99054\tvalidation_0-error:0.01995\tvalidation_0-error@0.6:0.02077\n",
      "[19]\tvalidation_0-auc:0.99074\tvalidation_0-error:0.01940\tvalidation_0-error@0.6:0.02104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=['auc', 'error', 'error@0.6'], feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=20, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.fit(x_train, y_train, eval_set=[(x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9806010928961748\n",
      "Precision:  0.9888285024154589\n",
      "Recall:  0.9897249924448474\n",
      "F1:  0.9892765443286513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "print(\"Accuracy: \", accuracy_score(y_pred, y_test))\n",
    "print(\"Precision: \", precision_score(y_pred, y_test))\n",
    "print(\"Recall: \", recall_score(y_pred, y_test))\n",
    "print(\"F1: \", f1_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
